议题名称：“HAMi：让开源 GPU 调度赋能 d.run 的 AI 开发者”

---

## 1.封面页

- 标题：HAMi：让开源 GPU 调度赋能 d.run 的 AI 开发者
- 副标题：基于 vGPU 动态切分的算力云实践
- 演讲者：船长（samzong） DaoCloud 产品负责人
- 日期：2025-11-30
- 活动名称：HAMi Meetup 上海站

---

## 2.个人介绍页

布局：左右分屏，左侧为演讲者照片，右侧为演讲者介绍。

内容点：
- 姓名：船长(samzong)
- 职位：@DaoCloud 产品负责人
- 职责：
    - 在 DaoCloud 负责 d.run 产品及大模型推理加速方向
    - 长期在企业级 GPU 资源管理和云平台交付中踩坑
- 开源经历: 
    - 长期活跃于 #Kubernetes、#HAMi、#Karmada、#vLLM、#llm-d 等项目。
    - 关注 GPU 调度、模型推理加速、云原生分布式工程实践。

---

## 3. 目录页

- 章节1：快闪 d.run 介绍
- 章节2：算力云 SaaS 租赁业务的挑战
- 章节3：HAMi 如何赋能 d.run 与 AI 开发者
- 章节4：Demo 分享

---

## 章节1：快闪 d.run 介绍

### 4. d.run 介绍
标题：D.run 企业级算力调度平台
副标题：打通算力-模型-应用的企业级服务平台

内容点：已有，留空

---

### 5. 算力云服务介绍
标题：算力云服务
副标题：让算力更自由

内容点：已有，留空

---

## 章节2：算力云 SaaS 租赁业务的挑战

### 6. SaaS 租赁业务的真实问题
标题：SaaS 租赁业务的真实问题
副标题：与企业 GPU 资源管理的差异

内容点：

> 企业问题
- GPU 资源天然粗粒度
- 不同业务模型导致严重碎片化
- 多团队、多租户隔离导致利用率进一步下降
- 训练/推理/图形混部难
- 简短数据：企业平均 GPU 利用率 20–40%

结论：企业的问题是：“资源不均匀”，“调度失衡”

> SaaS 租赁业务问题

内容点：
- 供需波动导致资源池持续失衡，租户行为极度不可预测。有人跑 3 小时就走，有人挂 7 天不动。固定 GPU 刀法只会被拉低资源利用率。
- 资源利用率：SaaS 靠量，不靠几个大客户。
- 成本结构敏感：GPU 是成本中心，不是资产；利用率差 10%，毛利差一倍。无法压榨 GPU，就不存在盈利模型。

结论：算力云的问题是：“资源不够用、不好卖、卖不稳”。

---

### 7. 成本结构

企业场景下，GPU 属于资产，一次性投入摊销到使用周期。
而在算力云的场景下，GPU 属于成本中心，小部分自持，大部分来自于对于上游供应商的租用，也就一位持续产生租用成本。

所以，算力云只有使用才会产生真正的收益。

GPU 单位成本 = 
  GPU 供给成本
  + 电力成本
  + 机房成本
  + 网络/存储成本
  + 运维成本
  + 碎片损失成本
  + 风险缓冲成本

---

### 8. 从 SaaS 角度看 GPU 来源
在 SaaS 里，GPU 来源主要三类：
- 租用型（主流）
    - 来自 IDC/第三方厂商
    - 按月、按季、按年租
    - 价格包含机柜、电力、网络、维护
- 共享型（次主流）
    - 与企业合作，由企业提供闲置卡
    - 只做做资源整合与调度
    - 利润按分成方式
- 自建机房型（少数）
    - 大型厂商如 AWS/Azure/超大规模玩家
    - 重资产型，成本高

---

### 9. 定价模型

标题：定价模型
副标题：利用率驱动定价（Utilization Pricing）

内容点：
- SaaS 最重要的模型。 你卖的不是一张卡，而是“卡 × 利用率”。

举例：
- A100 卡成本价按小时算是 16 元
- 利用率 40%，你的真实成本是 40 元/小时
- 如果利用率做到 70%，真实成本只有 22.8 元

利用率变化，毛利变化巨大。

售卖价格 = GPU 单位成本 × (1 + 毛利率)

真实单位成本 = GPU 单位成本 / 有效利用率

因为 SaaS 场景中最贵的不是 GPU 本身，而是：
	•	GPU 租金
	•	利用率不足导致的碎片
	•	客户波动带来的闲置
	•	弹性供给的不可预期性

---

## 章节3：HAMi 如何赋能 d.run 与 AI 开发者

### 10. HAMi 的价值

标题：HAMi 的价值
副标题：降低碎片、提升利用率、提升供给弹性

内容点：
- vGPU 切片 → 降低碎片成本
- 动态调优 → 避免闲置成本
- 超配能力 → 提升单位租金密度（更多租户共享同一 GPU）
- 统一抽象 → 无限寿命化异构设备

总结：这就是 HAMi 的价值链：动态切片 → 超配 → 更高利用率 → 更低实际成本。

---

### 11. HAMi：技术能力与架构

标题：HAMi 解决的不是功能，而是结构性问题。

内容点：
- Kubernetes Device Plugin 框架整合
- vGPU/MIG 抽象能力
- 动态切分与回收机制
- 适配异构设备（GPU/NPU）
- 调度插件 + 资源编排接口
- 插件化设计，让平台实现差异化

加入一张 HAMi 的核心架构图（插件、调度器、虚拟化引擎）。

结论：HAMi 提供了一个稳定且可扩展的抽象层。

---

### 12. HAMi 带来的产品力增强（赋能开发者）

标题：容器实例临时GPU显存弹性扩容

内容点： 

- 根据应用运行过程中的真实显存负载，动态调整分配的 GPU 显存资源
- 正常情况下，应用原本应当触发 OOM（Out of Memory）时
- 系统可临时自动判断并扩大显存分配，无需重启容器，避免
- 中断任务，提高稳定性与资源利用率

---

### 13. DaoCloud 与 HAMi 的关系

标题：我们的角色与边界。

内容点：
- HAMi 初期由 DaoCloud 技术团队深度参与孵化
- 目前 DaoCloud工程师 持续贡献核心代码，及业务需求
- 依赖 HAMi 帮助我们在 SaaS 和企业场景推进 GPU 纳管的解决办法

---

### 14. d.run：基于 HAMi 的生产级落地

标题：从开源能力到商业交付。

重点：1-1.8 倍的动态超售比，GPU 利用率超 100%。

内容点：

6.1 vGPU 动态切分在 d.run 的角色
- 实现 GPU 切片级租赁
- 动态调优：根据租户需求与负载变化在线动态调整库存
- 配合调度策略实现超配能力
- 统一运维与监控能力（metrics、拓扑、负载）

6.2 d.run 的体系结构（可上架构图）
- 控制面（租户 / 审计 / 配额）
- 调度面（HAMi 插件 + 自研策略）
- 数据面（GPU 实际运行切片）
- 资源池化逻辑

6.3 实际收益（数据或案例）
- 利用率提升（示例：40% → 120%）
- 单 GPU 复用效率提升 1.8 倍

---

### 15. HAMi 对 d.run 企业级方案增强

标题：HAMi 同时赋能 D.run 企业级落地

内容点：
- 多租户隔离 + 资源池化
- 支持不同业务场景下的算法开发、训练、推理
- 国产异构卡统一纳管

总结：这次不过多介绍了，如果大家有兴趣可以再增加一些内容。

---

## 章节4：Demo 与 小广告

### 16. Demo 展示

标题： Demo

内容点：留白，我会直接放一个视频

---

### 17. 小广告：体验 D.run SaaS 以及 了解 d.run 企业级方案

标题：快速体验（小广告）

内容：

- d.run 直接注册使用
- 了解更多企业级方案，欢迎私聊
- 加微信社区，加入我们的讨论群（放个二维码）

---

### 18. 收尾

- 感谢蜜瓜智能 和 HAMi 社区贡献者 创建了这么一个优秀的项目
- 欢迎体验 d.run，或者了解 DaoCloud 开源

### 19. QA
